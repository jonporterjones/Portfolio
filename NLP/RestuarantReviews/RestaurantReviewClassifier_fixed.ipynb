{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summmary\n",
    "\n",
    "This notebook will show some very basic NLP capability.  \n",
    "Creating a binary classifier to classify restaurant reviews as positive or negative.  \n",
    "The purpose is to demonstrate the ability to learn from text by beating a naive baseline.\n",
    "\n",
    "# Data\n",
    "The dataset is taken from Kaggle (European Restaurant Reviews).  \n",
    "It will use only the text columns (ReviewTitle, Review) and the sentiment output class (Positive/Negative)\n",
    "\n",
    "# Approach\n",
    "The approach is very simple - use a pre-trained sentiment classifier from huggingface.  \n",
    "The chosen model is:  cardiffnlp/twitter-roberta-base-sentiment-latest  \n",
    "It is a fine-tuned version of RoBERTa using Twitter data and the TweetEval benchmark.  \n",
    "The intuition here is that sentiment classification will transfer well enough to do a good job on the European Restaurant Reviews dataset.  \n",
    "This represnts a pragmatic apprach to the sentiment classification task as beating the naive baseline can likely be done without a great deal of effort.\n",
    "\n",
    "This is certainly not the only way to do this, some other options:\n",
    "*  Use a pre-trained encoder to get an 2d output for each word in the input sequence, then train a traditional neural network classifier on this output.\n",
    "*  Fine tune an encoder model such as RoBERTa on this, or a more appropriate dataset.\n",
    "*  You could even do something like train a language model from scratch with gensim and use those encodings to train a traditional nueral network classifier.\n",
    "\n",
    "Note that this is a small 'toy' dataset and considering any of these other options in reality would only make sense with much more data specialized to the task at hand.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonporterjones/.pyenv/versions/3.12.4/envs/Portfolio/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "read data from csv into a pd dataframe.    \n",
    "combine the relevant text columns into a single column.  \n",
    "Split X, y into train/test sets.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_review_data: pd.DataFrame = pd.read_csv(\"European Restaurant Reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_review_data[\"ReviewText\"] = restaurant_review_data[\"Review Title\"] + \" \" + restaurant_review_data[\"Review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Restaurant Name</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Review Date</th>\n",
       "      <th>Review</th>\n",
       "      <th>ReviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>The Frog at Bercy Village</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Rude manager</td>\n",
       "      <td>May 2024 •</td>\n",
       "      <td>The manager became agressive when I said the c...</td>\n",
       "      <td>Rude manager The manager became agressive when...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>France</td>\n",
       "      <td>The Frog at Bercy Village</td>\n",
       "      <td>Negative</td>\n",
       "      <td>A big disappointment</td>\n",
       "      <td>Feb 2024 •</td>\n",
       "      <td>I ordered a beef fillet ask to be done medium,...</td>\n",
       "      <td>A big disappointment I ordered a beef fillet a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>France</td>\n",
       "      <td>The Frog at Bercy Village</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Pretty Place with Bland Food</td>\n",
       "      <td>Nov 2023 •</td>\n",
       "      <td>This is an attractive venue with welcoming, al...</td>\n",
       "      <td>Pretty Place with Bland Food This is an attrac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>France</td>\n",
       "      <td>The Frog at Bercy Village</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Great service and wine but inedible food</td>\n",
       "      <td>Mar 2023 •</td>\n",
       "      <td>Sadly I  used the high TripAdvisor rating too ...</td>\n",
       "      <td>Great service and wine but inedible food Sadly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>France</td>\n",
       "      <td>The Frog at Bercy Village</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Avoid- Worst meal in Rome - possibly ever</td>\n",
       "      <td>Nov 2022 •</td>\n",
       "      <td>From the start this meal was bad- especially g...</td>\n",
       "      <td>Avoid- Worst meal in Rome - possibly ever From...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country            Restaurant Name Sentiment  \\\n",
       "0  France  The Frog at Bercy Village  Negative   \n",
       "1  France  The Frog at Bercy Village  Negative   \n",
       "2  France  The Frog at Bercy Village  Negative   \n",
       "3  France  The Frog at Bercy Village  Negative   \n",
       "4  France  The Frog at Bercy Village  Negative   \n",
       "\n",
       "                                Review Title Review Date  \\\n",
       "0                               Rude manager  May 2024 •   \n",
       "1                       A big disappointment  Feb 2024 •   \n",
       "2               Pretty Place with Bland Food  Nov 2023 •   \n",
       "3   Great service and wine but inedible food  Mar 2023 •   \n",
       "4  Avoid- Worst meal in Rome - possibly ever  Nov 2022 •   \n",
       "\n",
       "                                              Review  \\\n",
       "0  The manager became agressive when I said the c...   \n",
       "1  I ordered a beef fillet ask to be done medium,...   \n",
       "2  This is an attractive venue with welcoming, al...   \n",
       "3  Sadly I  used the high TripAdvisor rating too ...   \n",
       "4  From the start this meal was bad- especially g...   \n",
       "\n",
       "                                          ReviewText  \n",
       "0  Rude manager The manager became agressive when...  \n",
       "1  A big disappointment I ordered a beef fillet a...  \n",
       "2  Pretty Place with Bland Food This is an attrac...  \n",
       "3  Great service and wine but inedible food Sadly...  \n",
       "4  Avoid- Worst meal in Rome - possibly ever From...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurant_review_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1502, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurant_review_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(restaurant_review_data[\"ReviewText\"],\n",
    "                                                    restaurant_review_data[\"Sentiment\"],\n",
    "                                                    test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "(1351,)\n",
      "(1351,)\n",
      "Test:\n",
      "(151,)\n",
      "(151,)\n"
     ]
    }
   ],
   "source": [
    "print('Train:')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('Test:')\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1351.000000\n",
       "mean       70.244264\n",
       "std        73.774759\n",
       "min         3.000000\n",
       "25%        30.000000\n",
       "50%        46.000000\n",
       "75%        80.500000\n",
       "max       650.000000\n",
       "Name: ReviewText, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get some summary statisitics on the number of tokens in the training data.\n",
    "# This will help to give some intuition on the number of tokens to use in the model.\n",
    "x_train.str.split().apply(len).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "\n",
    "Determine a naive baseline from the training data.  \n",
    "This is done solely based on the majority class.  \n",
    "Any classifier capable of learning from the training data must beat this baseline.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = round(sum(y_train == \"Positive\")/y_train.shape[0],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The majority class Positive occurs in 0.82 % of the training data.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The majority class Positive occurs in {baseline} % of the training data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "The model is a hugging face fine-tuned sentiment classifier.  \n",
    "It will output the probability of each class Positive/Negative/Neutral.  \n",
    "Coerce this output into a binary classifier Positive/Negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_outputs(model, model_inputs):\n",
    "    # Getting OOM errors trying to put the entire train set through the model.\n",
    "    # I can batch them by hand or with the PyTorch DataSet/DataLoader classes.\n",
    "    # In this case I will simply truncate inputs to 50 tokens, this will provide the entire input for about 1/2 of the training data.\n",
    "    # Intuition says this is enough data to determine sentiment accurately.\n",
    "    encoded_input = tokenizer(list(model_inputs), padding=True, truncation=True, max_length=50, return_tensors='pt')\n",
    "\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "    # Get logits output only from model into a np array\n",
    "    model_output = model_output[0].detach().numpy()\n",
    "\n",
    "    # Softmax to force to p(x) that adds to 1\n",
    "    model_output = softmax(model_output)\n",
    "\n",
    "    # Get the max arg for each input.\n",
    "    model_output = np.argmax(model_output, axis=1)\n",
    "\n",
    "    model_output = ['Negative' if output == 0 else 'Positive' for output in model_output]\n",
    "\n",
    "    return model_output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_train = get_model_outputs(model, x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "Evaluate by predicting first on training data then on test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train = accuracy_score(y_train, predicted_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.95\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy on training data: {round(accuracy_train,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for test set\n",
    "predicted_test = get_model_outputs(model, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_test = accuracy_score(y_test, predicted_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 0.95\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy on test data: {round(accuracy_train,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "This notebook demonstrated some very basic NLP techniques using pre-trained transformers (encoders).  \n",
    "The model used was fine-tuned on a sentiment classification task and this notebook proves the learning from this task transfers well to the Restaurant Review dataset.\n",
    "\n",
    "Train/Test accuracy of 95% beats the naive baseline of 82%.\n",
    "\n",
    "Any discussion of next-steps to go beyond 95% is outside of the scope of this notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Portfolio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
